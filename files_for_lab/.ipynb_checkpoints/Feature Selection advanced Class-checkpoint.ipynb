{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb820d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import statsmodels.api as sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c54c3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7744798c",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv')\n",
    "boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2da63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = \n",
    "X = \n",
    "X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217cf617",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_added_constant = sm.add_constant(X)\n",
    "# we need to add this constant value of 1 for the intercepts\n",
    "model = sm.OLS(y,X_added_constant).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f52be16",
   "metadata": {},
   "source": [
    "F-statistic and Prob (F-statsitic): The null hypothesis that all the coefficients of regressors are zero, hence a high p-value means the model is more significant.\n",
    "\n",
    "For each Coefficient:\n",
    "\n",
    "- t-statistic and P-value: the null hypothesis that this particular coefficient is zero, so a p-value is greater than 0.05, it means the H0 can't be rejected and this coefficient should be left out of the model. It is used as a measurement of whether the coefficient is significant. \n",
    "\n",
    "- 0.025 and 0.975: The two boundaries of the coefficient at 95% confidence interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92aa31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop([], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13f5885",
   "metadata": {},
   "source": [
    "## Activity 1\n",
    "\n",
    "Info about R2 and R2-adj\n",
    "\n",
    "-https://towardsdatascience.com/r-squared-vs-adjusted-r-squared-simplified-543993e69558\n",
    "\n",
    "-https://www.analyticsvidhya.com/blog/2020/07/difference-between-r-squared-and-adjusted-r-squared/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02eaec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_added_constant = sm.add_constant(X)\n",
    "# we need to add this constant value of 1 for the intercepts\n",
    "model2 = sm.OLS(y,X_added_constant).fit()\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8404041f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Healthcare for all: classification\n",
    "\n",
    "numerical = pd.read_csv('../numerical.csv')\n",
    "categorical = pd.read_csv('../categorical.csv')\n",
    "targets = pd.read_csv('../target.csv')\n",
    "print(targets['TARGET_B'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78ff411",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Our dataset is imbalanced. Category 0 (no answer) repreents 94.9% of the total rows\n",
    "#For demonstration purposes we'll use only numerical features\n",
    "\n",
    "data = pd.concat([numerical, targets['TARGET_B']], axis=1)\n",
    "print(data.shape)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fc1789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsampling\n",
    "\n",
    "category_0 = data[data['TARGET_B'] == 0]\n",
    "category_1 = data[data['TARGET_B'] == 1]\n",
    "\n",
    "#Sample documentation https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html\n",
    "category_0 = category_0.sample(len(category_1))\n",
    "print(category_0.shape)\n",
    "print(category_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6d0682",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([category_0, category_1], axis=0)\n",
    "#shuffling the data\n",
    "data = data.sample(frac=1)\n",
    "data['TARGET_B'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996e1592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsampling\n",
    "\n",
    "category_1 = category_1.sample(len(category_0), replace=True)\n",
    "print(category_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35bb351",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([category_0, category_1], axis=0)\n",
    "#shuffling the data\n",
    "data = data.sample(frac=1)\n",
    "print(data['TARGET_B'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0f625f",
   "metadata": {},
   "source": [
    "The simplest implementation of over-sampling is to duplicate random records from the minority class, which can cause overfitting.\n",
    "\n",
    "In down-sampling, the simplest technique involves removing random records from the majority class, which can cause loss of information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08beb34",
   "metadata": {},
   "source": [
    "### Upsampling with SMOTE\n",
    "\n",
    "The SMOTE algorithm can be broken down into following steps:\n",
    "\n",
    "  - Randomly pick a point from the minority class.\n",
    "  - Compute the k-nearest neighbors (for some pre-specified k) for this point.\n",
    "  - Add k new points somewhere between the chosen point and each of its neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c289ad46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE()\n",
    "y = data['TARGET_B']\n",
    "X = data.drop(['TARGET_B'], axis=1)\n",
    "X_sm, y_sm = smote.fit_resample(X, y)\n",
    "y_sm.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97943c9c",
   "metadata": {},
   "source": [
    "### Downsampling with TomekLinks\n",
    "- TomekLinks are pairs of very close instances, but of opposite classes. Removing the instances of the majority class of each pair increases the space between the two classes, facilitating the classification process.\n",
    "- It does not make the two classes equal but only removes the points from the majority class that are close to other points in minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b63e8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import TomekLinks\n",
    "tl = TomekLinks(sampling_strategy='majority')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6399000",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tl, y_tl = tl.fit_resample(X, y)\n",
    "y_tl.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DA_env",
   "language": "python",
   "name": "da_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
